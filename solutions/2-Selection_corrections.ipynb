{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4bfea9a2",
      "metadata": {
        "id": "4bfea9a2"
      },
      "source": [
        "# Notebook 2: Model selection and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c68cc40",
      "metadata": {
        "id": "1c68cc40"
      },
      "source": [
        "Notebook prepared by [Chloé-Agathe Azencott](http://cazencott.info) with the help of [Arthur Imbert](https://github.com/Henley13) and contributions from [Giann Karlo](https://www.giannkarlo.info/).\n",
        "\n",
        "In this notebook it is\n",
        "* evaluate a model on a test set\n",
        "* to choose the value of a hyperparameter of a learning algorithm\n",
        "* to understand the interest of polynomial regression and regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79209869",
      "metadata": {
        "id": "79209869"
      },
      "outputs": [],
      "source": [
        "# load numpy as np, matplotlib as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5deca0d2",
      "metadata": {
        "id": "5deca0d2"
      },
      "outputs": [],
      "source": [
        "plt.rc('font', **{'size': 12}) # sets the font size globally for the plots (in pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad551f26",
      "metadata": {
        "id": "ad551f26"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb973324",
      "metadata": {
        "id": "bb973324"
      },
      "source": [
        "## 1. Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b376b8c",
      "metadata": {
        "id": "3b376b8c"
      },
      "source": [
        "We will work with a dataset containing physicochemical information on a number of Portuguese wines (vinho verde), as well as the ratings given to them by people who tasted them. Our goal is to automate this process: we want to directly predict the rating of wines based on their physicochemical characteristics, in order to assist oenologists, improve wine production, and target the tastes of niche consumers.\n",
        "\n",
        "This dataset is available on the UCI Machine Learning Dataset Archive, where you will find many classic datasets: https://archive.ics.uci.edu/dataset/186/wine+quality. No need to download it, it is already in your directory, in the `data/winequality-white.csv` file. We will load it with pandas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9258fcb3",
      "metadata": {
        "id": "9258fcb3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/winequality-white.csv', # file name\n",
        "                   sep=\";\" # column separator\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58480745",
      "metadata": {
        "id": "58480745"
      },
      "source": [
        "**Alternatively:** If you need to download the file (for example on colab):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/CBIO-mines/fml-dassault-systems/main/data/winequality-white.csv\n",
        "\n",
        "df = pd.read_csv('winequality-white.csv', # filename\n",
        "                   sep=\";\" # column separator\n",
        "                   )"
      ],
      "metadata": {
        "id": "ncFYwz25FyrZ"
      },
      "id": "ncFYwz25FyrZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d36a84c8",
      "metadata": {
        "id": "d36a84c8"
      },
      "source": [
        "We can now examine this file directly in our notebook, for example by looking at the first lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed7121e",
      "metadata": {
        "id": "0ed7121e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ba6c42",
      "metadata": {
        "id": "b5ba6c42"
      },
      "source": [
        "### Creation of X and y data matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b670ded0",
      "metadata": {
        "id": "b670ded0"
      },
      "outputs": [],
      "source": [
        "X = np.array(df.drop(columns=['quality']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea20ba0a",
      "metadata": {
        "id": "ea20ba0a"
      },
      "outputs": [],
      "source": [
        "y = np.array(df['quality'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5016c63",
      "metadata": {
        "id": "a5016c63"
      },
      "outputs": [],
      "source": [
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b51426",
      "metadata": {
        "id": "e7b51426"
      },
      "source": [
        "**Question:** How many training examples are in the data? How many variables?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c644c14b",
      "metadata": {
        "id": "c644c14b"
      },
      "source": [
        "**Question:** What do you think about using linear regression to solve this problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01c9ea2",
      "metadata": {
        "id": "b01c9ea2"
      },
      "source": [
        "### Transformation into a binary classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b797d9",
      "metadata": {
        "id": "e0b797d9"
      },
      "outputs": [],
      "source": [
        "y = np.where(y >= 6, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df39d94",
      "metadata": {
        "id": "9df39d94"
      },
      "source": [
        "## 2. Separation of data into a training set and a test set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8485750",
      "metadata": {
        "id": "f8485750"
      },
      "source": [
        "To be able to evaluate a learning model in an unbiased way, we need to create a test set containing data on which the model has not been trained. This test set corresponds to “new” data.\n",
        "\n",
        "To do this, we will use the [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function of the scikit-learn `model_selection` module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd69aef",
      "metadata": {
        "id": "dfd69aef"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y,\n",
        "                                    test_size=0.3, # 30% of data in the test set\n",
        "                                    random_state=42 # random generator seed\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e59af18",
      "metadata": {
        "id": "6e59af18"
      },
      "source": [
        "Fixing the random generator seed allows us to get the same training and test sets by rerunning the command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6ebcfe",
      "metadata": {
        "id": "ba6ebcfe"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a0aa16",
      "metadata": {
        "id": "f0a0aa16"
      },
      "source": [
        "**Question:** How many samples does the training set (X_train, y_train) contain? And the test set (X_test, y_test)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c4cea0",
      "metadata": {
        "id": "a2c4cea0"
      },
      "source": [
        "### Transformation of variables\n",
        "We saw in Notebook 1 that it is more reasonable to center-reduce the variables before proceeding.\n",
        "\n",
        "Let's not forget that the test set is supposedly unknown at the time of training: we must use **only the training set** to center-reduce the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b49fb9",
      "metadata": {
        "id": "88b49fb9"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08494ac6",
      "metadata": {
        "id": "08494ac6"
      },
      "outputs": [],
      "source": [
        "# Create a \"standardizer\" and calibrate it to the training data\n",
        "std_scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "\n",
        "# Apply standardization to training data\n",
        "X_train_scaled = std_scaler.transform(X_train)\n",
        "\n",
        "# Apply standardization to test data\n",
        "X_test_scaled = std_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1030dc9",
      "metadata": {
        "id": "c1030dc9"
      },
      "source": [
        "## 3. Nearest neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177f1aa0",
      "metadata": {
        "id": "177f1aa0"
      },
      "source": [
        "We will now evaluate the ability of a nearest neighbors algorithm to classify wines.\n",
        "\n",
        "To do this, we use the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) class of the scikit-learn `neighbors` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb5c5eb",
      "metadata": {
        "id": "cdb5c5eb"
      },
      "outputs": [],
      "source": [
        "from sklearn import neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c099f3",
      "metadata": {
        "id": "51c099f3"
      },
      "source": [
        "### Training on the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f36731",
      "metadata": {
        "id": "28f36731"
      },
      "source": [
        "As in Notebook 1, we start by instantiating an object of the class that interests us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34027505",
      "metadata": {
        "id": "34027505"
      },
      "outputs": [],
      "source": [
        "model_knn = neighbors.KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a7bc4e",
      "metadata": {
        "id": "f0a7bc4e"
      },
      "source": [
        "We can then train it on the centered-reduced training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b491595d",
      "metadata": {
        "id": "b491595d"
      },
      "outputs": [],
      "source": [
        "model_knn.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58b800c",
      "metadata": {
        "id": "f58b800c"
      },
      "source": [
        "### Test set Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323488f1",
      "metadata": {
        "id": "323488f1"
      },
      "source": [
        "We can now use the classifier trained on the test data, still centered-reduced:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08ae2231",
      "metadata": {
        "id": "08ae2231"
      },
      "outputs": [],
      "source": [
        "y_pred_knn = model_knn.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e260bb",
      "metadata": {
        "id": "b2e260bb"
      },
      "source": [
        "### Performance evaluation\n",
        "\n",
        "Many metrics make it possible to evaluate the performance of a classification algorithm (see [the scikit-learn doc on this subject](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). The **confusion matrix** in particular allows you to visualize how many examples of each class receive each label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387f64b8",
      "metadata": {
        "id": "387f64b8"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb936f26",
      "metadata": {
        "id": "bb936f26"
      },
      "outputs": [],
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f7e72b",
      "metadata": {
        "id": "30f7e72b"
      },
      "source": [
        "**Question:** How many true positives are there? False negatives?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11fe1180",
      "metadata": {
        "id": "11fe1180"
      },
      "source": [
        "The confusion matrix can be summarized by the [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
        "\n",
        "**F1 score** is useful to evaluate the performance of a classification model. it combines two other important metrics: **precision** and **recall**. The F1 score is the harmonic mean of precision and recall, providing a single score that balances both.\n",
        "\n",
        "The F1 score is valuable when you have an imbalanced dataset, for example, a dataset for **misinformation** where 99% of posts are not fake and only 1% are. A model that just predicts _not fake_ every time would be 99% _accurate_, but it would be useless because it never finds the fake news. The F1 score provides a much better assessment in these cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe55daa",
      "metadata": {
        "id": "abe55daa"
      },
      "outputs": [],
      "source": [
        "print(\"F1 of kNN on the test set : %.2f\" % metrics.f1_score(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45de1ae",
      "metadata": {
        "id": "c45de1ae"
      },
      "source": [
        "## 4. Selecting the number of nearest neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fda654b",
      "metadata": {
        "id": "9fda654b"
      },
      "source": [
        "**Question:** How many nearest neighbors were used in the previous section? Rely on the documentation, for example by typing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96a5a052",
      "metadata": {
        "id": "96a5a052"
      },
      "outputs": [],
      "source": [
        "neighbors.KNeighborsClassifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6b4877e",
      "metadata": {
        "id": "a6b4877e"
      },
      "source": [
        "### Setting up cross validation\n",
        "\n",
        "The number of nearest neighbors (`n_neighbors`) is a **hyperparameter** of the nearest neighbors algorithm: it is not part of the parameters of the model learned by the algorithm, but we must set it ourselves before training.\n",
        "\n",
        "We will now *choose* this number of nearest neighbors by a **gridsearch** procedure, which consists of *comparing* the performances of models trained using predefined values ​​(the grid) of the hyperparameter.\n",
        "\n",
        "Heads up ! If we want to be able to use the test set to evaluate the generalization error of the model using the optimal value of the number of nearest neighbors, we cannot use it also for this selection step, because otherwise we could bias the model and overlearn.\n",
        "\n",
        "To compare our models **on the training set**, we will use **cross-validation**, once again thanks to the [model-selection](http://scikit-learn.org/stable/model_selection.html#model-selection) module from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb309b7",
      "metadata": {
        "id": "7eb309b7"
      },
      "outputs": [],
      "source": [
        "n_folds = 10\n",
        "\n",
        "# Create a KFold object which will allow cross-validation in n_folds folds\n",
        "kf = model_selection.KFold(n_splits=n_folds,\n",
        "                           shuffle=True, # mix the samples before creating the folds\n",
        "                           random_state=42\n",
        "                          )\n",
        "\n",
        "# Use kf to split the training set into n_folds folds.\n",
        "# kf.split returns an iterator (consumed after a loop).\n",
        "# To be able to use the same folds several times, we transform this iterator into a list of indices:\n",
        "kf_indices = list(kf.split(X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77055eaa",
      "metadata": {
        "id": "77055eaa"
      },
      "source": [
        "`kf_indices` contains 10 pairs of two index vectors.\n",
        "\n",
        "Each of these pairs corresponds to a fold.\n",
        "\n",
        "The first vector gives the indices of the samples forming the training part of this fold. The second gives the indices of the samples forming the test part of this fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5168a67d",
      "metadata": {
        "id": "5168a67d"
      },
      "outputs": [],
      "source": [
        "for (idx, fold) in enumerate(kf_indices):\n",
        "    print(\"The fold %d contains %d observations for training and %d observations for testing\" % (idx, len(fold[0]), len(fold[1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7befee3e",
      "metadata": {
        "id": "7befee3e"
      },
      "source": [
        "**Question:** How many times does each sample appear in the training portion of a fold? In the test part? (There is no need to write any code to answer.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7daac1",
      "metadata": {
        "id": "fb7daac1"
      },
      "source": [
        "### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4567d6d7",
      "metadata": {
        "id": "4567d6d7"
      },
      "outputs": [],
      "source": [
        "k_values = np.arange(3, 50, step=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc0210e2",
      "metadata": {
        "id": "dc0210e2"
      },
      "outputs": [],
      "source": [
        "k_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f4f638",
      "metadata": {
        "id": "97f4f638"
      },
      "source": [
        "**Question:** Why select only odd numbers of neighbors?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc797bc",
      "metadata": {
        "id": "1cc797bc"
      },
      "source": [
        "We will now use the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class of the scikit-learn `model_selection` module to determine the optimal value of the number of nearest neighbors by grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac19b5c",
      "metadata": {
        "id": "7ac19b5c"
      },
      "outputs": [],
      "source": [
        "# Instantiating a GridSearchCV object\n",
        "grid = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # predictor to evaluate\n",
        "                                    {'n_neighbors':k_values}, # hyperparameter value dictionary\n",
        "                                    cv=kf_indices, # cross-validation to use\n",
        "                                    scoring='f1' # performance evaluation metric\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25918e21",
      "metadata": {
        "id": "25918e21"
      },
      "source": [
        "We will also use the [time magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to measure the calculation time of a cell in our notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38af7775",
      "metadata": {
        "id": "38af7775"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Using this object on training data (centered-reduced)\n",
        "grid.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc9bf13",
      "metadata": {
        "id": "1bc9bf13"
      },
      "source": [
        "The optimal value of the hyperparameter is given by:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c35833e",
      "metadata": {
        "id": "7c35833e"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca49b48",
      "metadata": {
        "id": "eca49b48"
      },
      "source": [
        "The following code displays the performance of the model according to the value of the hyperparameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115bfefb",
      "metadata": {
        "id": "115bfefb"
      },
      "outputs": [],
      "source": [
        "mean_test_score = grid.cv_results_['mean_test_score']\n",
        "stde_test_score = grid.cv_results_['std_test_score'] / np.sqrt(n_folds) # standard error\n",
        "\n",
        "p = plt.plot(k_values, mean_test_score)\n",
        "plt.plot(k_values, (mean_test_score + stde_test_score), '--', color=p[0].get_color())\n",
        "plt.plot(k_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
        "plt.fill_between(k_values, (mean_test_score + stde_test_score),\n",
        "                 (mean_test_score - stde_test_score), alpha=0.2)\n",
        "\n",
        "best_index = np.where(k_values == grid.best_params_['n_neighbors'])[0][0]\n",
        "plt.scatter(k_values[best_index], mean_test_score[best_index])\n",
        "\n",
        "\n",
        "plt.xlabel('number of nearest neighbors')\n",
        "plt.ylabel('F1')\n",
        "plt.title(\"Performance (in cross-validation) along the grid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97343242",
      "metadata": {
        "id": "97343242"
      },
      "source": [
        "### Optimal nearest neighbor model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846d7b6f",
      "metadata": {
        "id": "846d7b6f"
      },
      "outputs": [],
      "source": [
        "print(\"Best F1 in cross-validation: %.3f\" % grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbafb19",
      "metadata": {
        "id": "7fbafb19"
      },
      "source": [
        "The model trained on the entire data provided to `grid.fit` with the best hyperparameter value(s) is given by `grid.best_estimator_`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24634a3d",
      "metadata": {
        "id": "24634a3d"
      },
      "outputs": [],
      "source": [
        "y_pred_knn_opt = grid.best_estimator_.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9c2628",
      "metadata": {
        "id": "2a9c2628"
      },
      "outputs": [],
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57738b9",
      "metadata": {
        "id": "b57738b9"
      },
      "outputs": [],
      "source": [
        "print(\"F1 of kNN (optimal k) on the test set : %.3f\" % metrics.f1_score(y_test, y_pred_knn_opt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cac8ebc",
      "metadata": {
        "id": "6cac8ebc"
      },
      "source": [
        "## 5. Regularized logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f11be3a",
      "metadata": {
        "id": "7f11be3a"
      },
      "source": [
        "### Performance of an unregularized logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e666b9eb",
      "metadata": {
        "id": "e666b9eb"
      },
      "source": [
        "We will now train a **logistic** regression (because we have a classification problem) *on the training set* and evaluate it *on the test set*.\n",
        "\n",
        "We use the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class from the `linear_model` module of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51abbf0f",
      "metadata": {
        "id": "51abbf0f"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297bd894",
      "metadata": {
        "id": "297bd894"
      },
      "outputs": [],
      "source": [
        "# Create a linear regression model\n",
        "model_rlog = linear_model.LogisticRegression(penalty=None) # model not regularized for the moment\n",
        "\n",
        "# Train this model on (X_train_scaled, y_train)\n",
        "model_rlog.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ee5eec",
      "metadata": {
        "id": "18ee5eec"
      },
      "outputs": [],
      "source": [
        "# Predict test set labels\n",
        "y_pred_rlog = model_rlog.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e82bff",
      "metadata": {
        "id": "40e82bff"
      },
      "outputs": [],
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rlog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e965c516",
      "metadata": {
        "id": "e965c516"
      },
      "outputs": [],
      "source": [
        "print(\"F1 score of a logistic regression on the test set: %.3f\" % metrics.f1_score(y_test, y_pred_rlog))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c740750",
      "metadata": {
        "id": "5c740750"
      },
      "source": [
        "**Question:** What do you think of the quality of the model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23f053b",
      "metadata": {
        "id": "f23f053b"
      },
      "source": [
        "### Model coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0a3f70",
      "metadata": {
        "id": "7c0a3f70"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of variables\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Display for each variable its coefficient in the model\n",
        "plt.scatter(range(num_features), # on the abscissa: indices of the variables\n",
        "            model_rlog.coef_ # on the ordinate: their weight in the model\n",
        "           )\n",
        "\n",
        "# Label the x-axis tick marks\n",
        "tmp = plt.xticks(range(num_features), # one mark per variable\n",
        "                 list(df.columns[:-1]),  # display variable name\n",
        "                 rotation=90, # turn labels 90 degrees\n",
        "                 fontsize=14)\n",
        "\n",
        "# Label the axes\n",
        "tmp = plt.xlabel('Variable', fontsize=14)\n",
        "tmp = plt.ylabel('Coefficient', fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the coefficients with their corresponding variable names\n",
        "for i, col_name in enumerate(df.columns[:-1]):\n",
        "    print(f\"{col_name}: {model_rlog.coef_[0][i]:.4f}\")"
      ],
      "metadata": {
        "id": "nSBIrPVGTLrY"
      },
      "id": "nSBIrPVGTLrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "699d6d66",
      "metadata": {
        "id": "699d6d66"
      },
      "source": [
        "### Ridge regularization\n",
        "\n",
        "We will now add an l2 (or ridge) regularization to this logistic regression.\n",
        "\n",
        "Here there are few variables and their coefficients take low values: it is not certain that regularization is necessary, but as this dataset has few variables, we can use it to look at the effect of regularization on the values ​​of the coefficients of the learned model.\n",
        "\n",
        "Let's start by giving ourselves a grid of values ​​for the regularization parameter `C`.\n",
        "\n",
        "Watch out! The larger `C` is, *the less* there is regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e90888",
      "metadata": {
        "id": "74e90888"
      },
      "outputs": [],
      "source": [
        "c_values = np.logspace(-6, 3, 50)\n",
        "c_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f99c7a",
      "metadata": {
        "id": "f0f99c7a"
      },
      "source": [
        "We will now not use `GridSearchCV` but implement our grid search ourselves, in order to have access to the values ​​of the coefficients of each of the models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c44b7d",
      "metadata": {
        "id": "95c44b7d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "f1_per_c = [] # to record the F1 score values ​​for each of the 50 values ​​of C\n",
        "weights_per_c = [] # to record the coefficients associated with each variable,\n",
        "                   # for the 50 values ​​of C\n",
        "for c_val in c_values:\n",
        "    # Create a logistic regression model regularized by the c_val parameter\n",
        "    model_ridge = linear_model.LogisticRegression(penalty='l2', C=c_val)\n",
        "\n",
        "    # Calculate the cross-validation performance of the model\n",
        "    f1 = model_selection.cross_val_score(model_ridge, # predictor to evaluate\n",
        "                                         X_train_scaled, y_train, # training data\n",
        "                                         cv=kf_indices, # cross-validation to use\n",
        "                                         scoring='f1' # performance evaluation metric\n",
        "                                         )\n",
        "    f1_per_c.append(f1)\n",
        "\n",
        "    # Train the model on the total training set\n",
        "    model_ridge.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Save regression coefficients\n",
        "    weights_per_c.append(model_ridge.coef_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b56ac2",
      "metadata": {
        "id": "86b56ac2"
      },
      "source": [
        "### Evolution of performance according to the regularization coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d4ef87",
      "metadata": {
        "id": "28d4ef87"
      },
      "outputs": [],
      "source": [
        "mean_test_score = np.mean(np.array(f1_per_c), axis=1)\n",
        "stde_test_score = np.std(np.array(f1_per_c), axis=1) / np.sqrt(n_folds) # standard error\n",
        "\n",
        "p = plt.plot(c_values, mean_test_score)\n",
        "plt.plot(c_values, (mean_test_score + stde_test_score), '--',\n",
        "         color=p[0].get_color()) # reuse the same color as before instead of moving forward\n",
        "plt.plot(c_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
        "plt.fill_between(c_values, (mean_test_score + stde_test_score),\n",
        "                 (mean_test_score - stde_test_score), alpha=0.2)\n",
        "\n",
        "\n",
        "plt.xscale('log') # use a logarithmic abscissa scale\n",
        "\n",
        "# Label the axes\n",
        "tmp = plt.xlabel('Value of C', fontsize=14)\n",
        "tmp = plt.ylabel('Average F1', fontsize=14)\n",
        "\n",
        "# Title\n",
        "tmp = plt.title(\"Performance (cross-validation) of logistic regression\", fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8b61d1",
      "metadata": {
        "id": "3f8b61d1"
      },
      "source": [
        "**Question:** How does the model error (in cross-validation) scale with the amount of regularization?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d869174",
      "metadata": {
        "id": "2d869174"
      },
      "source": [
        "### Optimal ridge regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1848d513",
      "metadata": {
        "id": "1848d513"
      },
      "outputs": [],
      "source": [
        "# Find the index of the optimal value of C\n",
        "best_C_idx = np.argmax(np.mean(f1_per_c, axis=1))\n",
        "\n",
        "# Optimal C value\n",
        "c_opt = c_values[best_C_idx]\n",
        "print(\"Optimal C value (ridge regression): %.3e\" % c_opt)\n",
        "\n",
        "# Corresponding MSE\n",
        "print(\"F1 score (cross-validation) of the optimal regularized logistic regression model: %.2f +/- %.2f\" %      (np.mean(np.array(f1_per_c)[best_C_idx]), # average value\n",
        "      np.std(np.array(f1_per_c)[best_C_idx]) # standard deviation\n",
        "     ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8372687",
      "metadata": {
        "id": "c8372687"
      },
      "source": [
        "### Evolution of regression coefficients as a function of regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65a9951",
      "metadata": {
        "id": "e65a9951"
      },
      "outputs": [],
      "source": [
        "# Create a figure\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Changing colors for better visualization\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'purple', 'pink', 'brown', 'orange', 'teal', 'coral', 'lightblue', 'lime', 'lavender', 'turquoise', 'darkgreen', 'tan', 'salmon', 'gold'])\n",
        "\n",
        "lines = plt.plot(c_values,\n",
        "                 weights_per_c # ordinate = values ​​of regression coefficients\n",
        "                )\n",
        "plt.xscale('log') # logarithmic scale in abscissa\n",
        "\n",
        "# Display again (at the abscissa 2x1e3) the regression coefficients obtained without regularization\n",
        "for coeff in model_rlog.coef_[0]:\n",
        "    plt.scatter([2e3], [coeff])\n",
        "\n",
        "# Mark the optimal value of C with a vertical bar\n",
        "plt.plot([c_opt, c_opt], [-0.75, 1.25], 'k--')\n",
        "\n",
        "# Show legend\n",
        "tmp = plt.legend(lines, # retrieve the identifier\n",
        "                 list(df.columns[:-1]), # name of each variable, excluding 'quality'\n",
        "                 frameon=False, # no frame around the legend\n",
        "                 loc=(1, 0),  # place the caption to the right of the image\n",
        "                 fontsize=14)\n",
        "\n",
        "tmp = plt.xlabel('Value of C', fontsize=14)\n",
        "tmp = plt.ylabel('Regression coefficient', fontsize=14)\n",
        "\n",
        "tmp = plt.title('Logistic regression', fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73177fb3"
      },
      "source": [
        "# Get the coefficients of the best estimator from the grid search\n",
        "optimal_coefficients = weights_per_c[best_C_idx]\n",
        "\n",
        "# Display the coefficients with their corresponding variable names\n",
        "for i, col_name in enumerate(df.columns[:-1]):\n",
        "    print(f\"{col_name}: {optimal_coefficients[i]:.4f}\")"
      ],
      "id": "73177fb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88d2969b",
      "metadata": {
        "id": "88d2969b"
      },
      "source": [
        "**Question:** How do the model coefficients change depending on the amount of regularization?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee49beaf",
      "metadata": {
        "id": "ee49beaf"
      },
      "source": [
        "**Question:** Do these coefficients seem consistent with those obtained for non-regularized logistic regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "715fa89f",
      "metadata": {
        "id": "715fa89f"
      },
      "source": [
        "## 6. Ridge regularization on a textbook case"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b7ce92a",
      "metadata": {
        "id": "1b7ce92a"
      },
      "source": [
        "To better understand ridge regularization, we will simulate a non-linear data set which will take the form of a sinusoidal curve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f841f9",
      "metadata": {
        "id": "a7f841f9"
      },
      "source": [
        "### Data simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e706038e",
      "metadata": {
        "id": "e706038e"
      },
      "outputs": [],
      "source": [
        "nb_samples = 30\n",
        "\n",
        "np.random.seed(13)\n",
        "\n",
        "# real model\n",
        "def true_model(X):\n",
        "    return np.cos(1.5 * np.pi * X) * 5\n",
        "\n",
        "# \"ground truth\" samples taken from the real model\n",
        "X_ground_truth = np.linspace(0, 1, 100).reshape(-1, 1)\n",
        "y_ground_truth = true_model(X_ground_truth)\n",
        "\n",
        "# data = observations taken from the real model then noisy\n",
        "X = np.sort(np.random.rand(nb_samples, 1))\n",
        "y = true_model(X)\n",
        "# adding noise\n",
        "y += np.random.randn(nb_samples, 1) * 0.3\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9540df",
      "metadata": {
        "id": "2d9540df"
      },
      "outputs": [],
      "source": [
        "# Draw the real model\n",
        "plt.plot(X_ground_truth, y_ground_truth, label=\"Real model\", linewidth=2)\n",
        "\n",
        "# View simulated data\n",
        "plt.scatter(X, y, label=\"Simulated data\", marker=\"o\")\n",
        "\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e415787",
      "metadata": {
        "id": "7e415787"
      },
      "source": [
        "### Training/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21026f05",
      "metadata": {
        "id": "21026f05"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72486b1",
      "metadata": {
        "id": "b72486b1"
      },
      "source": [
        "### Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95e20f2",
      "metadata": {
        "id": "e95e20f2"
      },
      "source": [
        "**Question:** How many variables do we have in our problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34ff32f",
      "metadata": {
        "id": "d34ff32f"
      },
      "source": [
        "Let's train a “classic” linear regression (like the one seen in Notebook 1) on `(X_train, y_train)` and evaluate its performance on the training set and on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3198669c",
      "metadata": {
        "id": "3198669c"
      },
      "source": [
        "**Question:** Why compare these two performances?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb95e36",
      "metadata": {
        "id": "bcb95e36"
      },
      "outputs": [],
      "source": [
        "# Training - initialize linear regression\n",
        "reg = linear_model.LinearRegression()\n",
        "# Train the linear model\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddaa3135",
      "metadata": {
        "id": "ddaa3135"
      },
      "source": [
        "#### Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc018747",
      "metadata": {
        "id": "dc018747"
      },
      "outputs": [],
      "source": [
        "# RMSE\n",
        "print(\"RMSE of a linear regression:\")\n",
        "# On the training set\n",
        "rmse_reg_train = metrics.root_mean_squared_error(y_train, reg.predict(X_train))\n",
        "print(\"\\r train: {0:0.2f}\".format(rmse_reg_train))\n",
        "# On the test set\n",
        "rmse_reg_test = metrics.root_mean_squared_error(y_test, reg.predict(X_test))\n",
        "print(\"\\r test: {0:0.2f}\".format(rmse_reg_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9085bed",
      "metadata": {
        "id": "e9085bed"
      },
      "source": [
        "We will now display the model learned on the previous graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0122e19",
      "metadata": {
        "id": "f0122e19"
      },
      "outputs": [],
      "source": [
        "# Draw the real model\n",
        "plt.plot(X_ground_truth, y_ground_truth, label=\"Real model\", linewidth=2)\n",
        "\n",
        "# Show learned model\n",
        "y_model = reg.predict(X_ground_truth)\n",
        "plt.plot(X_ground_truth, y_model, label=\"Model learned\", linewidth=2)\n",
        "\n",
        "# View simulated data\n",
        "plt.scatter(X_train, y_train, label=\"Simulated data (train)\", marker=\"o\")\n",
        "plt.scatter(X_test, y_test, label=\"Simulated data (test)\", marker=\"D\")\n",
        "\n",
        "# plot format\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Linear regression\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f05fb3f",
      "metadata": {
        "id": "8f05fb3f"
      },
      "source": [
        "**Question:** What do you think of the performance of linear regression here?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57331c08",
      "metadata": {
        "id": "57331c08"
      },
      "source": [
        "### Polynomial regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f4411b",
      "metadata": {
        "id": "e5f4411b"
      },
      "source": [
        "Polynomial regression consists of learning a non-linear model by learning a linear model on a new set of variables, formed from mononoms of the variables describing our data.\n",
        "\n",
        "Generally speaking, for a problem described by $p$ variables $(X_1, X_2, \\dots, X_p)$, a polynomial regression of degree $d$ is a linear regression on the variables $(X_1, X_2, \\dots, X_p, X_1^2, X_2^2 X_3^2, \\dots, X_p^2, \\dots, X_p^d)$. Note that we are thus creating a large number of variables that are correlated with each other; we gain in modeling finesse, but lose in model complexity, risk of overfitting, and the curse of dimensionality.\n",
        "\n",
        "Such a transformation is possible with the `PolynomialFeatures` class of `sklearn.preprocessing`.\n",
        "\n",
        "Here, we are regressing a line based on the powers of $X$ rather than $X$ alone: we are approximating the true model using a polynomial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8716f5",
      "metadata": {
        "id": "1a8716f5"
      },
      "outputs": [],
      "source": [
        "# calculation of powers of x, up to degree 15\n",
        "polynomial_features = preprocessing.PolynomialFeatures(degree=15)# , include_bias=False)\n",
        "\n",
        "# creation of corresponding datasets\n",
        "X_train_poly = polynomial_features.fit_transform(X_train)\n",
        "X_test_poly = polynomial_features.transform(X_test)\n",
        "X_ground_truth_poly = polynomial_features.transform(X_ground_truth)\n",
        "\n",
        "print(X_train_poly.shape)\n",
        "print(X_test_poly.shape)\n",
        "print(X_ground_truth_poly.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8188518",
      "metadata": {
        "id": "f8188518"
      },
      "source": [
        "**Question:** How many variables do we have now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2d5fce",
      "metadata": {
        "id": "6d2d5fce"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "reg_poly = linear_model.LinearRegression()\n",
        "reg_poly.fit(X_train_poly, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "511876ac",
      "metadata": {
        "id": "511876ac"
      },
      "source": [
        "#### Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04147329",
      "metadata": {
        "id": "04147329"
      },
      "outputs": [],
      "source": [
        "# RMSE\n",
        "print(\"RMSE of a polynomial regression:\")\n",
        "# On the training set\n",
        "rmse_reg_poly_train = metrics.root_mean_squared_error(y_train, reg_poly.predict(X_train_poly))\n",
        "print(\"\\r train: {0:0.2f}\".format(rmse_reg_poly_train))\n",
        "# On the test set\n",
        "rmse_reg_poly_test = metrics.root_mean_squared_error(y_test, reg_poly.predict(X_test_poly))\n",
        "print(\"\\r test: {0:0.2f}\".format(rmse_reg_poly_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227ca65c",
      "metadata": {
        "id": "227ca65c"
      },
      "source": [
        "**Question:** Compare the performance of the model on the training set and the test set. What to conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d7e9a79",
      "metadata": {
        "id": "1d7e9a79"
      },
      "source": [
        "We will now display the model learned on the previous graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964fdacb",
      "metadata": {
        "id": "964fdacb"
      },
      "outputs": [],
      "source": [
        "# Draw the real model\n",
        "plt.plot(X_ground_truth, y_ground_truth, label=\"Real model\", linewidth=2)\n",
        "\n",
        "# Show learned model\n",
        "plt.plot(X_ground_truth, reg_poly.predict(X_ground_truth_poly), label=\"Model learned\", linewidth=2)\n",
        "\n",
        "# View simulated data\n",
        "plt.scatter(X_train, y_train, label=\"Simulated data (train)\", marker=\"o\")\n",
        "plt.scatter(X_test, y_test, label=\"Simulated data (test)\", marker=\"D\")\n",
        "\n",
        "# plot format\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Polynomial regression\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.ylim([-6, 6])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a063932",
      "metadata": {
        "id": "6a063932"
      },
      "source": [
        "**Question:** What can you conclude about choosing polynomial regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff90675",
      "metadata": {
        "id": "0ff90675"
      },
      "source": [
        "#### Model coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff609e8",
      "metadata": {
        "id": "6ff609e8"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of variables\n",
        "num_features = X_train_poly.shape[1]\n",
        "\n",
        "# Display for each variable its coefficient in the model\n",
        "plt.scatter(range(num_features), # on the abscissa: indices of the variables\n",
        "            reg_poly.coef_ # on the ordinate: their weight in the model\n",
        "           )\n",
        "\n",
        "# Label the axes\n",
        "tmp = plt.xlabel('Variable', fontsize=14)\n",
        "tmp = plt.ylabel('Coefficient', fontsize=14)\n",
        "plt.yscale(\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e28fec3",
      "metadata": {
        "id": "8e28fec3"
      },
      "source": [
        "**Question:** What do you notice? Pay close attention to the scale of the coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28982080",
      "metadata": {
        "id": "28982080"
      },
      "source": [
        "### Ridge regularized polynomial regression\n",
        "\n",
        "As polynomial regression overfits, we will now apply a ridge regularization term to it to try to compensate for this effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf293516",
      "metadata": {
        "id": "cf293516"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "ridge_poly = linear_model.Ridge(alpha=0.01, random_state=13)\n",
        "ridge_poly.fit(X_train_poly, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42bf6ebe",
      "metadata": {
        "id": "42bf6ebe"
      },
      "source": [
        "#### Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b181e115",
      "metadata": {
        "id": "b181e115"
      },
      "outputs": [],
      "source": [
        "# RMSE\n",
        "print(\"RMSE of a regularized polynomial regression:\")\n",
        "# On the training set\n",
        "rmse_ridge_poly_train = metrics.root_mean_squared_error(y_train, ridge_poly.predict(X_train_poly))\n",
        "print(\"\\r train: {0:0.2f}\".format(rmse_ridge_poly_train))\n",
        "# On the test set\n",
        "rmse_ridge_poly_test = metrics.root_mean_squared_error(y_test, ridge_poly.predict(X_test_poly))\n",
        "print(\"\\r test: {0:0.2f}\".format(rmse_ridge_poly_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb632b2c",
      "metadata": {
        "id": "eb632b2c"
      },
      "source": [
        "**Question:** Compare the performance of the model on the training set and the test set. What to conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a50e592f",
      "metadata": {
        "id": "a50e592f"
      },
      "source": [
        "We will now display the model learned on the previous graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b23d99",
      "metadata": {
        "id": "38b23d99"
      },
      "outputs": [],
      "source": [
        "# Draw the real model\n",
        "plt.plot(X_ground_truth, y_ground_truth, label=\"Real model\", linewidth=2)\n",
        "\n",
        "# Show learned model\n",
        "plt.plot(X_ground_truth, ridge_poly.predict(X_ground_truth_poly), label=\"Model learned\", linewidth=2)\n",
        "\n",
        "# View simulated data\n",
        "plt.scatter(X_train, y_train, label=\"Simulated data (train)\", marker=\"o\")\n",
        "plt.scatter(X_test, y_test, label=\"Simulated data (test)\", marker=\"D\")\n",
        "\n",
        "# plot format\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Regularized polynomial regression\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cebc50",
      "metadata": {
        "id": "d6cebc50"
      },
      "source": [
        "**Question:** What can you conclude about choosing Ridge regularization?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cbdaa32",
      "metadata": {
        "id": "2cbdaa32"
      },
      "source": [
        "#### Model coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd8f09f",
      "metadata": {
        "id": "4bd8f09f"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of variables\n",
        "num_features = X_train_poly.shape[1]\n",
        "\n",
        "# Display for each variable its coefficient in the model\n",
        "plt.scatter(range(num_features), # on the abscissa: indices of the variables\n",
        "            ridge_poly.coef_ # on the ordinate: their weight in the model\n",
        "           )\n",
        "\n",
        "# Label the axes\n",
        "tmp = plt.xlabel('Variable', fontsize=14)\n",
        "tmp = plt.ylabel('Coefficient', fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f0712b",
      "metadata": {
        "id": "61f0712b"
      },
      "source": [
        "**Question:** What do you notice now? What is the effect of regularization on the model coefficients?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3df00d6",
      "metadata": {
        "id": "a3df00d6"
      },
      "source": [
        "### Lasso regularized polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a187804a",
      "metadata": {
        "id": "a187804a"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "lasso_poly = linear_model.Lasso(alpha=0.01, random_state=13)\n",
        "lasso_poly.fit(X_train_poly, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d92db273",
      "metadata": {
        "id": "d92db273"
      },
      "source": [
        "#### Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e0e1b1",
      "metadata": {
        "id": "f7e0e1b1"
      },
      "outputs": [],
      "source": [
        "# RMSE\n",
        "print(\"RMSE of a regularized polynomial regression:\")\n",
        "# On the training set\n",
        "rmse_lasso_poly_train = metrics.root_mean_squared_error(y_train, lasso_poly.predict(X_train_poly))\n",
        "print(\"\\r train: {0:0.2f}\".format(rmse_lasso_poly_train))\n",
        "# On the test set\n",
        "rmse_lasso_poly_test = metrics.root_mean_squared_error(y_test, lasso_poly.predict(X_test_poly))\n",
        "print(\"\\r test: {0:0.2f}\".format(rmse_lasso_poly_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f099b28f",
      "metadata": {
        "id": "f099b28f"
      },
      "source": [
        "We will now display the model learned on the previous graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "257d0acf",
      "metadata": {
        "id": "257d0acf"
      },
      "outputs": [],
      "source": [
        "# Draw the real model\n",
        "plt.plot(X_ground_truth, y_ground_truth, label=\"Real model\", linewidth=2)\n",
        "\n",
        "# Show learned model\n",
        "plt.plot(X_ground_truth, lasso_poly.predict(X_ground_truth_poly), label=\"Model learned\", linewidth=2)\n",
        "\n",
        "# View simulated data\n",
        "plt.scatter(X_train, y_train, label=\"Simulated data (train)\", marker=\"o\")\n",
        "plt.scatter(X_test, y_test, label=\"Simulated data (test)\", marker=\"D\")\n",
        "\n",
        "# plot format\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"l1 regularized polynomial regression\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5aa405",
      "metadata": {
        "id": "6d5aa405"
      },
      "source": [
        "#### Model coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8abc95",
      "metadata": {
        "id": "9e8abc95"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of variables\n",
        "num_features = X_train_poly.shape[1]\n",
        "\n",
        "# Display for each variable its coefficient in the model\n",
        "plt.scatter(range(num_features), # on the abscissa: indices of the variables\n",
        "            lasso_poly.coef_ # on the ordinate: their weight in the model\n",
        "           )\n",
        "\n",
        "# Label the axes\n",
        "tmp = plt.xlabel('Variable', fontsize=14)\n",
        "tmp = plt.ylabel('Coefficient', fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "We reached the end of this notebook. Here is a summary of what we have covered, with the key takeaways:\n",
        "- We used the `scikit-learn` library to classify wine quality from continuous variables (wine features).\n",
        "- We tried a first classifier model: [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (after data scaling).\n",
        "- We evaluated the model perfomance based on a confusion matrix, and using the F1 score, which balances both **precision** and **recall**.\n",
        "- We used cross-validation and grid search to find the best F1 score by testing a range of numbers representing neighbors. **Cross-validation** allows to assess how well a model generalizes to unseen data by splitting the dataset into multiple subsets. **Grid search** enables hyperparameter optimization by systematically testing combinations or range of different values for hyperparameters, such as the number of neighbors.\n",
        "\n",
        "We manually performed a grid search on the effects of regularization by testing the hyperparameter `C`, remember, the larger `C` is, the less the is regularization. Finally, we explored ridge regularization on polynomial regression. We saw how a polynomial function of degree 15 can overfit the _ground truth_, but after applying a reguarization technique (ridge or lasso), there is a better fit."
      ],
      "metadata": {
        "id": "BscpJ8-ID6Vm"
      },
      "id": "BscpJ8-ID6Vm"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}