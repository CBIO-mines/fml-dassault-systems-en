{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 4 : Trees and Ensemble Methods\n",
        "Notebook prepared by [Chlo√©-Agathe Azencott](http://cazencott.info) and contributions from [Giann Karlo](https://www.giannkarlo.info/).\n",
        "\n",
        "In this notebook, we will discover decision trees and ensemble methods (random forests, gradient boosting)."
      ],
      "metadata": {
        "id": "FQhKQET0W9PV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-oIWMiVWzqp"
      },
      "outputs": [],
      "source": [
        "# load numpy as np, matplotlib as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('font', **{'size': 12}) # sets the global font size for plots (in pt)"
      ],
      "metadata": {
        "id": "Ubb2rUodXEu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1UQUKOZOXHPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "The goal of this notebook is to use the visual description of a mushroom to predict whether it is edible or not.\n",
        "\n",
        "The data is available in `data/mushrooms.csv`. It comes from the dataset https://archive.ics.uci.edu/ml/datasets/Mushroom but slightly modified.\n",
        "\n",
        "It contains a first line (header) describing the columns, then one line per mushroom. The values of the different variables are all represented by letters; here is their meaning:\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
        "4. bruises: bruises=t,no=f\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\n",
        "8. gill-size: broad=b,narrow=n\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
        "10. stalk-shape: enlarging=e,tapering=t\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
        "16. veil-type: partial=p,universal=u\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
        "18. ring-number: none=n,one=o,two=t\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
        "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
        "\n",
        "The first column tells us the class of each mushroom, 'e' for edible and 'p' for poisonous."
      ],
      "metadata": {
        "id": "oeO665t5XTXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternatively:** If you need to download the file (e.g., on Colab), uncomment the following two lines:"
      ],
      "metadata": {
        "id": "T0fpRNe4amjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/CBIO-mines/fml-dassault-systems/main/data/mushrooms.csv\n",
        "\n",
        "df = pd.read_csv(\"mushrooms.csv\")"
      ],
      "metadata": {
        "id": "zfRETwTaaj-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('data/mushrooms.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "I9IqMtxGXI3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "G_2SehPEapoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting variables to numerical values"
      ],
      "metadata": {
        "id": "PwpQDwXKat-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our variables are currently *categorical.*\n",
        "\n",
        "For example, for the \"cap shape\" variable, `b` corresponds to a bell cap, `c` to a conical cap, `f` to a flat cap, `k` to a knobbed cap, `s` to a sunken cap, and `x` to a convex cap.\n",
        "\n",
        "To work with this data, we need to convert these categories into numerical values.\n",
        "\n",
        "One possibility is to convert each letter into a number between 0 and the total number of categories, using [preprocessing.LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
        "\n",
        "This encoding is not necessarily ideal: an algorithm that uses Euclidean distance will consider a convex cap (`x` converted to 5) to be closer to a sunken cap (`s` converted to 4) than to a conical cap (`c` converted to 1), which doesn't make much sense. However, this is not a problem for algorithms based on decision trees, which treat categories as such and not as numerical values. The conversion is only necessary for implementation reasons.\n",
        "\n",
        "[One-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features) is generally a better choice. Note, however, that it has the disadvantage of increasing the number of variables and creating correlated variables."
      ],
      "metadata": {
        "id": "OLhnSAydaxCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "uahGZjayar5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "rAeZs4o2a2Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe our data again:"
      ],
      "metadata": {
        "id": "HfWKI3lOa5CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jG84Vnmfa7Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the X and y data matrices"
      ],
      "metadata": {
        "id": "mVX3EZaQa-pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df.drop(columns=['class']))\n",
        "y = np.array(df['class'])\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "ROiYNxFia8wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** How many samples (examples) does our dataset contain? How many variables?"
      ],
      "metadata": {
        "id": "6wIsNhfTbFyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Selection and evaluation framework\n",
        "\n",
        "We can now split our data into a training set and a test set, and then fix a split of the training set into 10 folds for cross-validation.\n",
        "\n",
        "You will need the functions [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
      ],
      "metadata": {
        "id": "eny4fXw0bI0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "fxGdUuyBa8tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and test set"
      ],
      "metadata": {
        "id": "6-B3xNqUbSg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START OF YOUR CODE\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "### END OF YOUR CODE"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FLO2EQ13bS9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation"
      ],
      "metadata": {
        "id": "xnfU6BHAcIsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_folds = 10\n",
        "\n",
        "### START OF YOUR CODE\n",
        "\n",
        "# Create a KFold object that will allow cross-validation in n_folds folds\n",
        "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Use kf to split the training set into n_folds folds.\n",
        "# kf.split returns an iterator (consumed after a loop).\n",
        "# To use the same folds multiple times, we convert this iterator into a list of indices:\n",
        "kf_indices = list(kf.split(X_train))\n",
        "\n",
        "### END OF YOUR CODE"
      ],
      "metadata": {
        "id": "vhhccUMZbUle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Decision Tree\n",
        "\n",
        "We will now use a decision tree to learn a classifier on our data.\n",
        "\n",
        "Decision trees are implemented in the [DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) class of scikit-learn's `tree` module."
      ],
      "metadata": {
        "id": "9ytDy35qcNs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "1qWPVtkqcR3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree with default hyperparameters\n",
        "\n",
        "Let's determine the F1 score using cross-validation for a decision tree with default hyperparameters in scikit-learn:"
      ],
      "metadata": {
        "id": "u1EycfV2cUjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tree_default = tree.DecisionTreeClassifier()\n",
        "\n",
        "f1_tree_default = model_selection.cross_val_score(model_tree_default, # predictor to evaluate\n",
        "                                                  X_train, y_train, # training data\n",
        "                                                  cv=kf_indices, # cross-validation to use\n",
        "                                                  scoring='f1' # performance evaluation metric\n",
        "                                                  )\n",
        "print(\"F1 of a decision tree (default) in cross-validation: %.3f +/- %.3f\" % (np.mean(f1_tree_default), np.std(f1_tree_default)))"
      ],
      "metadata": {
        "id": "gMTH0W6dcdUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What do you think of this performance?"
      ],
      "metadata": {
        "id": "UdsO50gbcj4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation of decision tree depth\n",
        "\n",
        "By default (see the documentation), we used a decision tree with maximum depth. We will now consider the tree depth (`max_depth`) as a hyperparameter to optimize using a grid search. We are re-using and adapting the code used for kNN in Notebook 3.\n",
        "\n",
        "Let's start by defining the grid:"
      ],
      "metadata": {
        "id": "d9EYU_8NcmpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_values = np.arange(2, 31)"
      ],
      "metadata": {
        "id": "b96fN6AMcqBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_values"
      ],
      "metadata": {
        "id": "CAdKFC0a0Vfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
      ],
      "metadata": {
        "id": "QwGDrXBdczkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiation of a GridSearchCV object\n",
        "grid_tree = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), # predictor to evaluate\n",
        "                                         {'max_depth': d_values}, # dictionary of hyperparameter values\n",
        "                                         cv=kf_indices, # cross-validation to use\n",
        "                                         scoring='f1' # performance evaluation metric\n",
        "                                         )"
      ],
      "metadata": {
        "id": "sQ3x_jrGc1N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Use this object on the training data\n",
        "grid_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zLnWdxr8c5q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal hyperparameter value is given by:"
      ],
      "metadata": {
        "id": "ocWFg_fuc5SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_tree.best_params_)"
      ],
      "metadata": {
        "id": "PoPThfaedA9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code allows displaying the model's performance according to the hyperparameter value:"
      ],
      "metadata": {
        "id": "RhmO6q_zdDOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test_score = grid_tree.cv_results_['mean_test_score']\n",
        "stde_test_score = grid_tree.cv_results_['std_test_score'] / np.sqrt(n_folds) # standard error\n",
        "\n",
        "plt.plot(d_values, mean_test_score)\n",
        "plt.plot(d_values, (mean_test_score + stde_test_score), '--', color='steelblue')\n",
        "plt.plot(d_values, (mean_test_score - stde_test_score), '--', color='steelblue')\n",
        "plt.fill_between(d_values, (mean_test_score + stde_test_score),\n",
        "                 (mean_test_score - stde_test_score), alpha=0.2)\n",
        "\n",
        "best_index = np.where(d_values == grid_tree.best_params_['max_depth'])[0][0]\n",
        "plt.scatter(d_values[best_index], mean_test_score[best_index])\n",
        "\n",
        "\n",
        "plt.xlabel('maximum depth')\n",
        "plt.ylabel('F1')\n",
        "plt.title(\"Performance (in cross-validation) along the grid\")"
      ],
      "metadata": {
        "id": "U6baZ1hadFKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What do you think of this performance?"
      ],
      "metadata": {
        "id": "ccCVMCx3dH7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal decision tree"
      ],
      "metadata": {
        "id": "zNqSx0KEdNDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best F1 in cross-validation: %.3f\" % grid_tree.best_score_)"
      ],
      "metadata": {
        "id": "LWq2oX09dIf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now retrieve the optimal decision tree:"
      ],
      "metadata": {
        "id": "GPCkcY9jdgC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tree_best = grid_tree.best_estimator_"
      ],
      "metadata": {
        "id": "1fCZ1cEAdjPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Interpretation of the decision tree\n",
        "\n",
        "### Visualization\n",
        "\n",
        "The [plot_tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) method of scikit-learn's `tree` module allows us to visualize the optimal decision tree:"
      ],
      "metadata": {
        "id": "s2PenV4XdlFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(25, 20))\n",
        "tree.plot_tree(model_tree_best, fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qRVO5JxLdsKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Does the learned model seem interpretable to you?"
      ],
      "metadata": {
        "id": "K6NIbizcdu1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Importance\n",
        "\n",
        "To interpret the decision tree, we can also look at the importance of each variable. It is greater the more the variable helps to reduce the tree's classification error."
      ],
      "metadata": {
        "id": "nQbhs_30dyOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Display decision tree importances\n",
        "plt.scatter(range(num_features), model_tree_best.feature_importances_,\n",
        "           label=\"Decision Tree\")\n",
        "\n",
        "# Legend\n",
        "tmp = plt.legend(fontsize=14)\n",
        "\n",
        "# X-axis\n",
        "plt.xlabel('Variables', fontsize=14)\n",
        "feature_names = list(df.columns[1:])\n",
        "tmp = plt.xticks(range(num_features), feature_names,\n",
        "                 rotation=90, fontsize=14)\n",
        "\n",
        "# Y-axis\n",
        "tmp = plt.ylabel('Importance', fontsize=14)\n",
        "\n",
        "# Title\n",
        "tmp = plt.title('Variable Importance', fontsize=16)"
      ],
      "metadata": {
        "id": "qZzCT52kdxCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison to logistic regression\n",
        "\n",
        "We can also compare these importances to the regression coefficients of a logistic regression:"
      ],
      "metadata": {
        "id": "dBVuGZksd5s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "4mJGesiAd9gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a regularized logistic regression model (Ridge regularization, or \"L2\") with a grid search on the value of the regularization coefficient C, using cross-validation:"
      ],
      "metadata": {
        "id": "Hw8X9dDQeAvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_values = np.logspace(-3, 3, 50)\n",
        "\n",
        "### START OF YOUR CODE\n",
        "\n",
        "# Center and scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "std_scaler = StandardScaler()\n",
        "X_train_scaled = std_scaler.fit_transform(X_train)\n",
        "X_test_scaled = std_scaler.transform(X_test)\n",
        "\n",
        "# Instantiation of a GridSearchCV object\n",
        "grid_logreg = model_selection.GridSearchCV(linear_model.LogisticRegression(solver='liblinear'),\n",
        "                                          {'C': c_values},\n",
        "                                          cv=kf_indices,\n",
        "                                          scoring='f1')\n",
        "\n",
        "# Application to training data\n",
        "grid_logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "### END OF YOUR CODE"
      ],
      "metadata": {
        "id": "uwF8pxkxeBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best F1 in cross-validation: %.3f\" % grid_logreg.best_score_)"
      ],
      "metadata": {
        "id": "O02edLFheFhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Compare this performance to that of the decision tree."
      ],
      "metadata": {
        "id": "raNYna-UeHoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Scale importances between 0 and 1\n",
        "tree_importances = model_tree_best.feature_importances_\n",
        "tree_importances_min = np.min(tree_importances)\n",
        "tree_importances_max = np.max(tree_importances)\n",
        "tree_importances = (tree_importances-tree_importances_min)/(tree_importances_max-tree_importances_min)\n",
        "\n",
        "# Display decision tree importances\n",
        "plt.bar(range(num_features), tree_importances,\n",
        "           label=\"Decision Tree\", width=0.4)\n",
        "\n",
        "# Scale absolute values of linear model coefficients between 0 and 1\n",
        "logreg_coeffs = np.abs(grid_logreg.best_estimator_.coef_[0])\n",
        "logreg_coeffs_min = np.min(logreg_coeffs)\n",
        "logreg_coeffs_max = np.max(logreg_coeffs)\n",
        "logreg_coeffs = (logreg_coeffs-logreg_coeffs_min)/(logreg_coeffs_max-logreg_coeffs_min)\n",
        "\n",
        "# Display logistic regression importances\n",
        "plt.bar((np.arange(num_features)+0.4), logreg_coeffs,\n",
        "           label=\"Logistic Regression\", width=0.4)\n",
        "\n",
        "\n",
        "# Legend\n",
        "tmp = plt.legend(fontsize=14)\n",
        "\n",
        "# X-axis\n",
        "plt.xlabel('Variables', fontsize=14)\n",
        "feature_names = list(df.columns[1:])\n",
        "tmp = plt.xticks(range(num_features), feature_names,\n",
        "                 rotation=90, fontsize=14)\n",
        "\n",
        "# Y-axis\n",
        "tmp = plt.ylabel('Importance', fontsize=14)\n",
        "\n",
        "# Title\n",
        "tmp = plt.title('Variable Importance', fontsize=16)"
      ],
      "metadata": {
        "id": "uEmfq1xHeJVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** How do these importances compare?"
      ],
      "metadata": {
        "id": "W8lYyc-ReNh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Random Forest\n",
        "\n",
        "Can we improve the decision tree's performance using an ensemble method? We will use a random forest here, implemented in the [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) class of scikit-learn's `ensemble` module."
      ],
      "metadata": {
        "id": "0f8z6190eQZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble"
      ],
      "metadata": {
        "id": "5S6afE2uePC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation of the number of trees and their maximum depth.\n",
        "\n",
        "We will now consider two hyperparameters, the maximum depth of each tree (`max_depth`), and the number of trees in the forest (`n_estimators`)."
      ],
      "metadata": {
        "id": "4FPg9LnceVDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by defining the grid:"
      ],
      "metadata": {
        "id": "D-FuiNRnebsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_values = np.array([3, 4, 10])\n",
        "n_values = np.array([10, 20, 50, 100, 200])#, 100, 200, 500])"
      ],
      "metadata": {
        "id": "145SnBWReai8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
      ],
      "metadata": {
        "id": "Jq1vOw5Degk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START OF YOUR CODE\n",
        "\n",
        "# Instantiation of a GridSearchCV object\n",
        "grid_rf = model_selection.GridSearchCV(ensemble.RandomForestClassifier(),\n",
        "                                      {'max_depth': d_values, 'n_estimators': n_values},\n",
        "                                      cv=kf_indices,\n",
        "                                      scoring='f1')\n",
        "\n",
        "# Use this object on the training data\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "### END OF YOUR CODE"
      ],
      "metadata": {
        "id": "HbsR8YiQei2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal hyperparameter values are given by:"
      ],
      "metadata": {
        "id": "ArS_bm8Gem-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_rf.best_params_)"
      ],
      "metadata": {
        "id": "Y9ok0cwzeocW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can display the model's performance according to the value of each of the two hyperparameters:"
      ],
      "metadata": {
        "id": "uUlcbALaep8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape scores into a 2D array\n",
        "mean_test_score_array = np.reshape(grid_rf.cv_results_['mean_test_score'], (len(d_values), len(n_values)))\n",
        "std_test_score_array = np.reshape(grid_rf.cv_results_['std_test_score'], (len(d_values), len(n_values)))"
      ],
      "metadata": {
        "id": "hD_IMQoKesg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (idx, d) in enumerate(d_values):\n",
        "    mean_test_score = mean_test_score_array[idx, :]\n",
        "    stde_test_score = std_test_score_array[idx, :] / np.sqrt(n_folds) # standard error\n",
        "\n",
        "    p = plt.plot(n_values, mean_test_score, label=\"Max depth = %d\" % d)\n",
        "    plt.plot(n_values, (mean_test_score + stde_test_score), '--', color=p[0].get_color())\n",
        "    plt.plot(n_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
        "    plt.fill_between(n_values, (mean_test_score + stde_test_score),\n",
        "                     (mean_test_score - stde_test_score), alpha=0.2)\n",
        "\n",
        "    # Display best hyperparameters\n",
        "    if d == grid_rf.best_params_['max_depth']:\n",
        "        best_ntree_index = np.where(n_values == grid_rf.best_params_['n_estimators'])[0][0]\n",
        "        plt.scatter(n_values[best_ntree_index], mean_test_score[best_ntree_index],\n",
        "                   marker='*', s=200, color='red')\n",
        "\n",
        "plt.legend(loc=(1.1, 0))\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel('F1')\n",
        "plt.title(\"Performance (in cross-validation) along the grid\")\n",
        "plt.xscale('log') # use a logarithmic scale on the x-axis"
      ],
      "metadata": {
        "id": "HMLkPyR6evrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** How does the performance of random forests compare to previous performances?"
      ],
      "metadata": {
        "id": "JVkoM79zeyBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal random forest"
      ],
      "metadata": {
        "id": "nTbOvAsye0Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best F1 in cross-validation: %.3f\" % grid_rf.best_score_)"
      ],
      "metadata": {
        "id": "siWF3fdbeyXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now retrieve the optimal decision tree:"
      ],
      "metadata": {
        "id": "NMpgPD3ie3OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf_best = grid_rf.best_estimator_"
      ],
      "metadata": {
        "id": "LSPB3pZ7e5iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Importance\n",
        "\n",
        "We can once again look at the importance of each variable, for the best random forest model:"
      ],
      "metadata": {
        "id": "eI3CFY0Ge7ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Scale importances between 0 and 1\n",
        "tree_importances = model_tree_best.feature_importances_\n",
        "tree_importances_min = np.min(tree_importances)\n",
        "tree_importances_max = np.max(tree_importances)\n",
        "tree_importances = (tree_importances-tree_importances_min)/(tree_importances_max-tree_importances_min)\n",
        "\n",
        "# Display decision tree importances\n",
        "plt.bar(range(num_features), tree_importances,\n",
        "           label=\"Decision Tree\", width=0.3)\n",
        "\n",
        "# Scale absolute values of linear model coefficients between 0 and 1\n",
        "logreg_coeffs = np.abs(grid_logreg.best_estimator_.coef_[0])\n",
        "logreg_coeffs_min = np.min(logreg_coeffs)\n",
        "logreg_coeffs_max = np.max(logreg_coeffs)\n",
        "logreg_coeffs = (logreg_coeffs-logreg_coeffs_min)/(logreg_coeffs_max-logreg_coeffs_min)\n",
        "\n",
        "# Display logistic regression importances\n",
        "plt.bar((np.arange(num_features)+0.3), logreg_coeffs,\n",
        "           label=\"Logistic Regression\", width=0.3)\n",
        "\n",
        "# Scale importances between 0 and 1\n",
        "rf_importances = model_rf_best.feature_importances_\n",
        "rf_importances_min = np.min(rf_importances)\n",
        "rf_importances_max = np.max(rf_importances)\n",
        "rf_importances = (rf_importances-rf_importances_min)/(rf_importances_max-rf_importances_min)\n",
        "\n",
        "# Display forest importances\n",
        "plt.bar((np.arange(num_features)+0.6),  rf_importances,\n",
        "           label=\"Random Forest\", width=0.3)\n",
        "\n",
        "\n",
        "# Legend\n",
        "tmp = plt.legend()\n",
        "\n",
        "# X-axis\n",
        "plt.xlabel('Variables')\n",
        "feature_names = list(df.columns[1:])\n",
        "tmp = plt.xticks(range(num_features), feature_names,\n",
        "                 rotation=90, fontsize=14)\n",
        "\n",
        "# Y-axis\n",
        "tmp = plt.ylabel('Importance')\n",
        "\n",
        "# Title\n",
        "tmp = plt.title('Variable Importance')"
      ],
      "metadata": {
        "id": "F_tkJmKhe-RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What are the most important variables now? How does this compare to previous models?"
      ],
      "metadata": {
        "id": "SE3nqdt2fBPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Gradient Boosting\n",
        "\n",
        "Gradient boosting is implemented in scikit-learn in the [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html?highlight=boosting#sklearn.ensemble.GradientBoostingClassifier) class of the `ensemble` module."
      ],
      "metadata": {
        "id": "Ty-PVmlJfDdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation and hyperparameter selection\n",
        "\n",
        "As with random forests, we will optimize the number of estimators and the depth of the trees here."
      ],
      "metadata": {
        "id": "3kaoAJ0DfH1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_values = np.array([10, 20, 50, 100, 200])\n",
        "d_values = np.array([3, 4, 7])"
      ],
      "metadata": {
        "id": "1as_3PKbfKij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
      ],
      "metadata": {
        "id": "McNbT06nfOPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START OF YOUR CODE\n",
        "\n",
        "# Instantiation of a GridSearchCV object\n",
        "grid_boost = model_selection.GridSearchCV(ensemble.GradientBoostingClassifier(),\n",
        "                                         {'n_estimators': n_values, 'max_depth': d_values},\n",
        "                                         cv=kf_indices,\n",
        "                                         scoring='f1')\n",
        "\n",
        "# Use this object on the training data\n",
        "grid_boost.fit(X_train, y_train)\n",
        "\n",
        "### END OF YOUR CODE"
      ],
      "metadata": {
        "id": "6A0hn5nffPht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal hyperparameter values are given by:"
      ],
      "metadata": {
        "id": "GDLCp45EfSei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_boost.best_params_)"
      ],
      "metadata": {
        "id": "qDDJA0erfS-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can display the model's performance according to the value of each of the two hyperparameters:"
      ],
      "metadata": {
        "id": "eXzsPS0ZfVWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape scores into a 2D array\n",
        "mean_test_score_array = np.reshape(grid_boost.cv_results_['mean_test_score'], (len(d_values), len(n_values)))\n",
        "std_test_score_array = np.reshape(grid_boost.cv_results_['std_test_score'], (len(d_values), len(n_values)))"
      ],
      "metadata": {
        "id": "RogtA-E6fXOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (idx, d) in enumerate(d_values):\n",
        "    mean_test_score = mean_test_score_array[idx, :]\n",
        "    stde_test_score = std_test_score_array[idx, :] / np.sqrt(n_folds) # standard error\n",
        "\n",
        "    p = plt.plot(n_values, mean_test_score, label=\"Max depth = %d\" % d)\n",
        "    plt.plot(n_values, (mean_test_score + stde_test_score), '--', color=p[0].get_color())\n",
        "    plt.plot(n_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
        "    plt.fill_between(n_values, (mean_test_score + stde_test_score),\n",
        "                     (mean_test_score - stde_test_score), alpha=0.2)\n",
        "\n",
        "    # Display best hyperparameters\n",
        "    if d == grid_boost.best_params_['max_depth']:\n",
        "        best_ntree_index = np.where(n_values == grid_boost.best_params_['n_estimators'])[0][0]\n",
        "        plt.scatter(n_values[best_ntree_index], mean_test_score[best_ntree_index],\n",
        "                   marker='*', s=200, color='red')\n",
        "\n",
        "plt.legend(loc=(1.1, 0))\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel('F1')\n",
        "plt.title(\"Performance (in cross-validation) along the grid\")\n",
        "plt.xscale('log') # use a logarithmic scale on the x-axis"
      ],
      "metadata": {
        "id": "VYi51ZW-fZAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** How does the performance of gradient boosting evolve based on hyperparameter values? How does it compare to previous performances?"
      ],
      "metadata": {
        "id": "DBB2_3dGfbW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal Boosting"
      ],
      "metadata": {
        "id": "tfHhrWI8fdn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best F1 in cross-validation: %.3f\" % grid_boost.best_score_)"
      ],
      "metadata": {
        "id": "wDDY0VlwffS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now retrieve the optimal decision tree:"
      ],
      "metadata": {
        "id": "dNKt0qCpfhmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_boost_best = grid_boost.best_estimator_"
      ],
      "metadata": {
        "id": "St4MVGirfjT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Importance\n",
        "\n",
        "We can once again look at the importance of each variable:"
      ],
      "metadata": {
        "id": "CdX7hVKAfk2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "### Decision Tree\n",
        "# Scale importances between 0 and 1\n",
        "tree_importances = model_tree_best.feature_importances_\n",
        "tree_importances_min = np.min(tree_importances)\n",
        "tree_importances_max = np.max(tree_importances)\n",
        "tree_importances = (tree_importances-tree_importances_min)/(tree_importances_max-tree_importances_min)\n",
        "\n",
        "# Display decision tree importances\n",
        "plt.bar(range(num_features), tree_importances,\n",
        "           label=\"Decision Tree\", width=0.2)\n",
        "\n",
        "### Logistic Regression\n",
        "# Scale absolute values of linear model coefficients between 0 and 1\n",
        "logreg_coeffs = np.abs(grid_logreg.best_estimator_.coef_[0])\n",
        "logreg_coeffs_min = np.min(logreg_coeffs)\n",
        "logreg_coeffs_max = np.max(logreg_coeffs)\n",
        "logreg_coeffs = (logreg_coeffs-logreg_coeffs_min)/(logreg_coeffs_max-logreg_coeffs_min)\n",
        "\n",
        "# Display logistic regression importances\n",
        "plt.bar((np.arange(num_features)+0.2), logreg_coeffs,\n",
        "           label=\"Logistic Regression\", width=0.2)\n",
        "\n",
        "### Random Forest\n",
        "# Scale importances between 0 and 1\n",
        "rf_importances = model_rf_best.feature_importances_\n",
        "rf_importances_min = np.min(rf_importances)\n",
        "rf_importances_max = np.max(rf_importances)\n",
        "rf_importances = (rf_importances-rf_importances_min)/(rf_importances_max-rf_importances_min)\n",
        "\n",
        "# Display forest importances\n",
        "plt.bar((np.arange(num_features)+0.4),  rf_importances,\n",
        "           label=\"Random Forest\", width=0.2)\n",
        "\n",
        "### Boosting\n",
        "# Scale importances between 0 and 1\n",
        "boost_importances = model_boost_best.feature_importances_\n",
        "boost_importances_min = np.min(boost_importances)\n",
        "boost_importances_max = np.max(boost_importances)\n",
        "boost_importances = (boost_importances-boost_importances_min)/(boost_importances_max-boost_importances_min)\n",
        "\n",
        "# Display boosting importances\n",
        "plt.bar((np.arange(num_features)+0.6),  boost_importances,\n",
        "           label=\"Boosting\", width=0.2)\n",
        "\n",
        "# Legend\n",
        "tmp = plt.legend()\n",
        "\n",
        "# X-axis\n",
        "plt.xlabel('Variables')\n",
        "feature_names = list(df.columns[1:])\n",
        "tmp = plt.xticks(range(num_features), feature_names,\n",
        "                 rotation=90, fontsize=14)\n",
        "\n",
        "# Y-axis\n",
        "tmp = plt.ylabel('Importance')\n",
        "\n",
        "# Title\n",
        "tmp = plt.title('Variable Importance')"
      ],
      "metadata": {
        "id": "gsidFHJUfoXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What are the most important variables now? How does this compare to previous models?"
      ],
      "metadata": {
        "id": "RCx1EFcHfsJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Final Model\n",
        "\n",
        "**Question:** Which of these models do you choose as the most performant for classifying mushrooms in the test set?\n",
        "\n",
        "You will now evaluate the model you have chosen on the test set:"
      ],
      "metadata": {
        "id": "6jj48BqTfvzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = model_boost_best # TODO : insert the name of the model you have chosen here.\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = my_model.predict(X_test)"
      ],
      "metadata": {
        "id": "AK7Li2cWf1gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"F1 of the chosen model on the test set: %.3f\" % metrics.f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "MenK21a0f3WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What do you think of this performance? Is there a risk of overfitting?"
      ],
      "metadata": {
        "id": "_i2L6VESf6-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "To better interpret the results, we can also visualize the confusion matrix:"
      ],
      "metadata": {
        "id": "6EffnaGFf9WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ],
      "metadata": {
        "id": "TQZaOXZHf8Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What do you think of this confusion matrix? Is it satisfactory? Remember that we are trying to predict if a mushroom is edible."
      ],
      "metadata": {
        "id": "YrSRI2DXgCkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curve\n",
        "\n",
        "We can also evaluate the model's performance **before thresholding**, i.e., by using the predicted numerical scores rather than binary labels, thanks to a [ROC Curve](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics).\n",
        "\n",
        "The scores before thresholding of a scikit-learn classification model are accessible through the `predict_proba` method."
      ],
      "metadata": {
        "id": "rJdSJ3ksgEgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_scores =  my_model.predict_proba(X_test)[:, 1]\n",
        "y_pred_scores"
      ],
      "metadata": {
        "id": "XCBJYg_9gNan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_scores.shape\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "8jEy3uOUOo7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = metrics.precision_recall_curve(y_test, y_pred_scores)\n",
        "max_fpr = 0.01\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "max_index_where_fpr_acceptable = np.where(fpr <= max_fpr)[0][-1]\n",
        "max_tpr = tpr[max_index_where_fpr_acceptable]\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "\n",
        "plt.plot(fpr, tpr, lw=2)\n",
        "\n",
        "# diagonal\n",
        "plt.plot([0, 1], [0, 1], color='k')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "\n",
        "# Add more ticks to the axes\n",
        "plt.xticks(np.arange(0, 1.1, 0.1))\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "\n",
        "plt.xlabel('false positive rate')\n",
        "plt.ylabel('true positive rate')\n",
        "plt.title(\"ROC curve of the final model\")\n",
        "\n",
        "# Add vertical line at max_fpr and horizontal line at max_tpr\n",
        "plt.plot([max_fpr, max_fpr], [0, max_tpr], color='red', linestyle='--', label=f'FPR = {max_fpr:.2f}')\n",
        "plt.plot([0, max_fpr], [max_tpr, max_tpr], color='red', linestyle='--')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Drzv7-45gRf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This curve can also be used to determine the true positive rate corresponding to a given false positive rate, and to determine the corresponding threshold:"
      ],
      "metadata": {
        "id": "lpRul0WJgZdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The true positive rate corresponding to a false positive rate not exceeding %.f %% is %.f %%\" % ((100*max_fpr), (100*max_tpr)))\n",
        "print(\"It corresponds to a threshold of %.2f on the model's predictions.\" % thresholds[max_index_where_fpr_acceptable])"
      ],
      "metadata": {
        "id": "0GJ2h75Kgcpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "We reached the end of this notebook, where we explored decision trees and ensemble methods for classifying mushrooms as edible or poisonous. Here is a summary of what we have covered, with the key takeaways:\n",
        "- We loaded and preprocessed the mushroom dataset, converting categorical features into numerical values using `LabelEncoder`.\n",
        "- We split the data into training and test sets and set up a K-Fold cross-validation strategy.\n",
        "- We trained and evaluated a Decision Tree Classifier with default hyperparameters, then optimized its `max_depth` using `GridSearchCV` and cross-validation, observing the impact of depth on performance.\n",
        "- We visualized the optimal decision tree and analyzed variable importances, comparing them to the coefficients of a Logistic Regression model.\n",
        "- We explored ensemble methods:\n",
        "    - **Random Forest:** We tuned the number of trees (`n_estimators`) and `max_depth` using `GridSearchCV`, observing improved performance compared to a single decision tree.\n",
        "    - **Gradient Boosting:** We also tuned `n_estimators` and `max_depth` for a Gradient Boosting Classifier, comparing its performance and variable importances to the other models.\n",
        "- We selected the best performing model (Gradient Boosting in this case) and evaluated its performance on the held-out test set using the F1 score.\n",
        "- We analyzed the Confusion Matrix to understand the types of errors made by the model and considered the implications for a mushroom classification task.\n",
        "- We examined the ROC curve to evaluate the model's performance at different thresholds and identified the true positive rate at a low false positive rate, along with the corresponding threshold.\n",
        "\n",
        "Overall, ensemble methods like Random Forests and Gradient Boosting generally outperformed a single Decision Tree on this dataset, demonstrating the power of combining multiple models. Variable importance analysis provided insights into which features were most influential in the classification process for each model."
      ],
      "metadata": {
        "id": "5KIlicpgAr_O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5FrRyYQVAtGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}